{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(', ')', '+', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '=', 'div', 'times', 'X', 'y']\n"
     ]
    }
   ],
   "source": [
    "# make a list of folder inside of folder Extracted_images\n",
    "import os\n",
    "path = 'Extracted_images'\n",
    "folders = []\n",
    "for folder in os.listdir(path):\n",
    "    folders.append(folder)\n",
    "print(folders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the folders list to array\n",
    "folders = np.array(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['(', ')', '+', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8',\n",
       "       '9', '=', 'div', 'times', 'X', 'y'], dtype='<U5')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Label Encoder to convert the folders name to numbers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 16, 17,\n",
       "       15, 18], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array = []\n",
    "image_label = []\n",
    "\n",
    "for i in folders:\n",
    "    path = 'Extracted_images/' + i\n",
    "    for image in os.listdir(path):\n",
    "        image = cv2.imread(path + '/' + image)\n",
    "        image = cv2.resize(image, (24,24))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image_array.append(image)\n",
    "        image_label.append(le.transform([i]))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array = np.array(image_array)\n",
    "image_label = np.array(image_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array = image_array.astype('float32')/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        ...,\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157]],\n",
       "\n",
       "       [[0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        ...,\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157]],\n",
       "\n",
       "       [[0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        ...,\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        ...,\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157]],\n",
       "\n",
       "       [[0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        ...,\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157]],\n",
       "\n",
       "       [[0.00390619, 0.00390619, 0.00390619, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        [0.00389081, 0.00392157, 0.00390619, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        [0.00390619, 0.00390619, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        ...,\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157],\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(image_array, image_label, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((146372, 24, 24), (36594, 24, 24), (146372, 1), (36594, 1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# import layers, models\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "#import model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 11, 11, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 9, 9, 64)          18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 4, 4, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4, 4, 64)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               131200    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 19)                1235      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 159507 (623.07 KB)\n",
      "Trainable params: 159507 (623.07 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "# Convolutional and max-pooling layers\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(24, 24, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Dropout layer\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Flatten layer\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Dense layers\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "model.add(layers.Dense(len(folders), activation='softmax'))  # num_classes is the number of classes you want to predict\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4575/4575 [==============================] - 101s 21ms/step - loss: 2.7359 - accuracy: 0.1006 - val_loss: 2.7403 - val_accuracy: 0.0969\n",
      "Epoch 2/10\n",
      "4575/4575 [==============================] - 107s 23ms/step - loss: 2.7327 - accuracy: 0.1003 - val_loss: 2.7417 - val_accuracy: 0.0969\n",
      "Epoch 3/10\n",
      "4575/4575 [==============================] - 120s 26ms/step - loss: 2.7324 - accuracy: 0.1001 - val_loss: 2.7402 - val_accuracy: 0.1014\n",
      "Epoch 4/10\n",
      "4575/4575 [==============================] - 111s 24ms/step - loss: 2.7321 - accuracy: 0.1012 - val_loss: 2.7397 - val_accuracy: 0.1014\n",
      "Epoch 5/10\n",
      "4575/4575 [==============================] - 93s 20ms/step - loss: 2.7318 - accuracy: 0.1005 - val_loss: 2.7405 - val_accuracy: 0.1014\n",
      "Epoch 6/10\n",
      "4575/4575 [==============================] - 110s 24ms/step - loss: 2.7318 - accuracy: 0.1007 - val_loss: 2.7413 - val_accuracy: 0.0969\n",
      "Epoch 7/10\n",
      "4575/4575 [==============================] - 124s 27ms/step - loss: 2.7316 - accuracy: 0.1006 - val_loss: 2.7400 - val_accuracy: 0.1014\n",
      "Epoch 8/10\n",
      "4575/4575 [==============================] - 96s 21ms/step - loss: 2.7316 - accuracy: 0.1011 - val_loss: 2.7401 - val_accuracy: 0.1014\n",
      "Epoch 9/10\n",
      "4575/4575 [==============================] - 93s 20ms/step - loss: 2.7315 - accuracy: 0.1009 - val_loss: 2.7408 - val_accuracy: 0.0947\n",
      "Epoch 10/10\n",
      "4575/4575 [==============================] - 105s 23ms/step - loss: 2.7315 - accuracy: 0.1016 - val_loss: 2.7404 - val_accuracy: 0.0947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1943904feb0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 2500 into shape (1,100,100,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\baral\\Desktop\\math_eqn\\app.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/math_eqn/app.ipynb#X23sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m             \u001b[39mprint\u001b[39m(original_value)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/math_eqn/app.ipynb#X23sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m             \u001b[39m# print(f'Prediction for {filename}: {pred}')\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/math_eqn/app.ipynb#X23sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/math_eqn/app.ipynb#X23sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Replace 'your_directory' with the path of the directory you want to search\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/math_eqn/app.ipynb#X23sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m predict_images(\u001b[39m'\u001b[39;49m\u001b[39mC:\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mUsers\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mbaral\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mDesktop\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mmath_eqn\u001b[39;49m\u001b[39m'\u001b[39;49m, model)\n",
      "\u001b[1;32mc:\\Users\\baral\\Desktop\\math_eqn\\app.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/math_eqn/app.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/math_eqn/app.ipynb#X23sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/math_eqn/app.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39;49mreshape(\u001b[39m1\u001b[39;49m ,\u001b[39m100\u001b[39;49m, \u001b[39m100\u001b[39;49m,\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/math_eqn/app.ipynb#X23sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(img)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/math_eqn/app.ipynb#X23sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(pred)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 2500 into shape (1,100,100,1)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def predict_images(directory, model):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.jpg'):\n",
    "            img = cv2.imread(os.path.join(directory, filename))\n",
    "            img = cv2.resize(img, (50, 50))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img = img.astype('float32')\n",
    "            img = img/255\n",
    "            img = img.reshape(1 ,24, 24,1)\n",
    "            \n",
    "            pred = model.predict(img)\n",
    "            pred = np.argmax(pred)\n",
    "            original_value = le.inverse_transform([44])\n",
    "            print(original_value)\n",
    "\n",
    "            # print(f'Prediction for {filename}: {pred}')\n",
    "\n",
    "# Replace 'your_directory' with the path of the directory you want to search\n",
    "predict_images('C:\\\\Users\\\\baral\\\\Desktop\\\\math_eqn', model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
